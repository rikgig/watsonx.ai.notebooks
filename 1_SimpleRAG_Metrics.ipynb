{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.11",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Use watsonx Granite Model Series, Chroma, and LangChain to answer questions (RAG)",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "markdown",
            "source": "#### Disclaimers\n\n- Use only Projects and Spaces that are available in watsonx context.\n\n## Notebook content\nThis notebook contains the steps and code to demonstrate support of Retrieval Augumented Generation in watsonx.ai. It introduces commands for data retrieval, knowledge base building & querying, and model testing.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n### About Retrieval Augmented Generation\nRetrieval Augmented Generation (RAG) is a versatile pattern that can unlock a number of use cases requiring factual recall of information, such as querying a knowledge base in natural language.\n\nIn its simplest form, RAG requires 3 steps:\n\n- Index knowledge base passages (once)\n- Retrieve relevant passage(s) from knowledge base (for every user query)\n- Generate a response by feeding retrieved passage into a large language model (for every user query)\n\n## Contents\n\nThis notebook contains the following parts:\n\n- [Setup](#setup)\n- [Document data loading](#data)\n- [Build up knowledge base](#build_base)\n- [Foundation Models on watsonx](#models)\n- [Generate a retrieval-augmented response to a question](#predict)\n- [Summary and next steps](#summary)\n",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "markdown",
            "source": "<a id=\"setup\"></a>\n##  Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "markdown",
            "source": "### Install and import the dependecies",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "!pip install \"langchain==0.3.7\" | tail -n 1\n!pip install \"ibm-watsonx-ai==1.1.23\" | tail -n 1\n!pip install \"langchain_ibm==0.3.3\" | tail -n 1\n!pip install \"wget==3.2\" | tail -n 1\n!pip install \"sentence-transformers==3.3.0\" | tail -n 1\n!pip install \"chromadb==0.5.18\" | tail -n 1\n!pip install \"pydantic==2.9.2\" | tail -n 1\n!pip install \"sqlalchemy==2.0.35\" | tail -n 1\n!pip install \"faiss-cpu==1.9.0\" | tail -n 1\n!pip install \"flashrank==0.2.9\" | tail -n 1\n\n!pip install \"langchain-community==0.3.7\" | tail -n 1\n!pip install \"pymupdf==1.24.13\" | tail -n 1",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "ae06c3cd-d072-4ffb-baf1-146267b97eb6"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain==0.3.7) (3.0.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai==1.1.23) (1.16.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm==0.3.3) (1.16.0)\nRequirement already satisfied: wget==3.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (3.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers==3.3.0) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.18) (0.4.8)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic==2.9.2) (4.11.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sqlalchemy==2.0.35) (3.0.1)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from faiss-cpu==1.9.0) (23.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sympy->onnxruntime->flashrank==0.2.9) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.7) (1.0.0)\nRequirement already satisfied: pymupdf==1.24.13 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (1.24.13)\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": "import os, getpass",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "f3816967-e69e-4225-a635-f0c9651e4202"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": "### watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>.\n**Link to directly add an API key** https://cloud.ibm.com/iam/apikeys \"\"Make sure that your are under the correct cloud instance**\n",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "markdown",
            "source": "### Defining the project id\nThe API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\n\n**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details).\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# My Environment\nos.environ[\"PROJECT_ID\"]=\"4f6edd25-9060-4a3f-a906-b3915545a5a9\"\napi_key = \"7j4m2zAuBZYdelHTzFz5OC0pwRtI09wz7BHsj_mc7Jse\"",
            "metadata": {
                "id": "ae42aec9-562a-4281-9466-9b3711b49bf1"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": "try:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")\n\ncredentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \") if ( api_key == \"\") else api_key\n}   ",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "778bc9a6-24af-4b82-b861-7ce765cb3100"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": "<a id=\"data\"></a>\n## Document data loading\n\nDownload the file with State of the Union.",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "print (credentials)",
            "metadata": {
                "id": "1ac85f6c-9eea-4912-823d-8bde516d45b6"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "{'url': 'https://us-south.ml.cloud.ibm.com', 'apikey': '7j4m2zAuBZYdelHTzFz5OC0pwRtI09wz7BHsj_mc7Jse'}\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": "import wget\n\nfilename = 'state_of_the_union.txt'\nurl = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/foundation_models/state_of_the_union.txt'\n\nif not os.path.isfile(filename):\n    wget.download(url, out=filename)",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "3dc02a14-3398-4d38-8578-81f778ddcd5b"
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": "<a id=\"build_base\"></a>\n## Build up knowledge base\n\nThe most common approach in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n\nIn this basic example, we take the State of the Union speech content (filename), split it into chunks, embed it using an open-source embedding model, load it into <a href=\"https://www.trychroma.com/\" target=\"_blank\" rel=\"noopener no referrer\">Chroma</a>, and then query it.",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\nloader = TextLoader(filename)\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_documents(documents)",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "fe83a8ab-c62a-4015-977e-aadd3d64589c"
            },
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": "### Create an embedding function\n\nNote that you can feed a custom embedding function to be used by chromadb. The performance of Chroma db may differ depending on the embedding model used. In following example we use watsonx.ai Embedding service. We can check available embedding models using `get_embedding_model_specs`",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "from ibm_watsonx_ai.foundation_models.utils import get_embedding_model_specs\n\nget_embedding_model_specs(credentials.get('url'))",
            "metadata": {
                "id": "cd6e14b2-0207-4e3b-b005-edbc450384cb"
            },
            "outputs": [
                {
                    "execution_count": 8,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "{'total_count': 7,\n 'limit': 100,\n 'first': {'href': 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2023-09-30&filters=function_embedding'},\n 'resources': [{'model_id': 'ibm/slate-125m-english-rtrvr',\n   'label': 'slate-125m-english-rtrvr',\n   'provider': 'IBM',\n   'source': 'IBM',\n   'functions': [{'id': 'autoai_rag'},\n    {'id': 'embedding'},\n    {'id': 'rerank'},\n    {'id': 'similarity'}],\n   'short_description': 'An embedding model. It has 125 million parameters and an embedding dimension of 768.',\n   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n   'input_tier': 'class_c1',\n   'output_tier': 'class_c1',\n   'number_params': '125m',\n   'limits': {'lite': {'call_time': '5m0s'},\n    'v2-professional': {'call_time': '10m0s'},\n    'v2-standard': {'call_time': '10m0s'}},\n   'lifecycle': [{'id': 'available', 'start_date': '2024-04-18'}]},\n  {'model_id': 'ibm/slate-125m-english-rtrvr-v2',\n   'label': 'slate-125m-english-rtrvr-v2',\n   'provider': 'IBM',\n   'source': 'IBM',\n   'functions': [{'id': 'embedding'}, {'id': 'rerank'}, {'id': 'similarity'}],\n   'short_description': 'An embedding model with 512 token limit. It has 125 million parameters and an embedding dimension of 768.',\n   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n   'input_tier': 'class_c1',\n   'output_tier': 'class_c1',\n   'number_params': '125m',\n   'limits': {'lite': {'call_time': '5m0s'},\n    'v2-professional': {'call_time': '10m0s'},\n    'v2-standard': {'call_time': '10m0s'}}},\n  {'model_id': 'ibm/slate-30m-english-rtrvr',\n   'label': 'slate-30m-english-rtrvr',\n   'provider': 'IBM',\n   'source': 'IBM',\n   'functions': [{'id': 'embedding'}, {'id': 'rerank'}, {'id': 'similarity'}],\n   'short_description': 'An embedding model. It has 30 million parameters and an embedding dimension of 384.',\n   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n   'input_tier': 'class_c1',\n   'output_tier': 'class_c1',\n   'number_params': '30m',\n   'limits': {'lite': {'call_time': '5m0s'},\n    'v2-professional': {'call_time': '10m0s'},\n    'v2-standard': {'call_time': '10m0s'}},\n   'lifecycle': [{'id': 'available', 'start_date': '2024-04-18'}]},\n  {'model_id': 'ibm/slate-30m-english-rtrvr-v2',\n   'label': 'slate-30m-english-rtrvr-v2',\n   'provider': 'IBM',\n   'source': 'IBM',\n   'functions': [{'id': 'embedding'}, {'id': 'rerank'}, {'id': 'similarity'}],\n   'short_description': 'An embedding model with 512 token limit. It has 30 million parameters and an embedding dimension of 384.',\n   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n   'input_tier': 'class_c1',\n   'output_tier': 'class_c1',\n   'number_params': '30m',\n   'limits': {'lite': {'call_time': '5m0s'},\n    'v2-professional': {'call_time': '10m0s'},\n    'v2-standard': {'call_time': '10m0s'}},\n   'lifecycle': [{'id': 'available', 'start_date': '2024-08-15'}]},\n  {'model_id': 'intfloat/multilingual-e5-large',\n   'label': 'multilingual-e5-large',\n   'provider': 'intfloat',\n   'source': 'intfloat',\n   'functions': [{'id': 'autoai_rag'},\n    {'id': 'embedding'},\n    {'id': 'rerank'},\n    {'id': 'similarity'}],\n   'short_description': 'An embedding model. It has 560 million parameters, has 24 layers and the embedding size is 1024.',\n   'long_description': 'This model gets continually trained on a mixture of multilingual datasets. It supports 100 languages from xlm-roberta.',\n   'input_tier': 'class_c1',\n   'output_tier': 'class_c1',\n   'number_params': '560m',\n   'limits': {'lite': {'call_time': '5m0s'},\n    'v2-professional': {'call_time': '10m0s'},\n    'v2-standard': {'call_time': '10m0s'}},\n   'lifecycle': [{'id': 'available', 'start_date': '2024-05-16'}]},\n  {'model_id': 'sentence-transformers/all-minilm-l12-v2',\n   'label': 'all-minilm-l12-v2',\n   'provider': 'sentence-transformers',\n   'source': 'sentence-transformers',\n   'functions': [{'id': 'embedding'}, {'id': 'rerank'}, {'id': 'similarity'}],\n   'short_description': 'An embedding model with 128 token limit. It has 33.4 million parameters and an embedding dimension of 384.',\n   'long_description': 'This model follows sentence transformers approach, it maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.',\n   'input_tier': 'class_c1',\n   'output_tier': 'class_c1',\n   'number_params': '33.4m',\n   'limits': {'lite': {'call_time': '5m0s'},\n    'v2-professional': {'call_time': '10m0s'},\n    'v2-standard': {'call_time': '10m0s'}},\n   'lifecycle': [{'id': 'available', 'start_date': '2024-05-16'}]},\n  {'model_id': 'sentence-transformers/all-minilm-l6-v2',\n   'label': 'all-minilm6-v2',\n   'provider': 'sentence-transformers',\n   'source': 'sentence-transformers',\n   'functions': [{'id': 'embedding'}, {'id': 'rerank'}, {'id': 'similarity'}],\n   'short_description': 'An embedding model with 128 token limit. It has 23 million parameters and an embedding dimension of 384.',\n   'long_description': 'This is a sentence-transformers model. It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.',\n   'input_tier': 'class_c1',\n   'output_tier': 'class_c1',\n   'number_params': '23m',\n   'limits': {'lite': {'call_time': '5m0s'},\n    'v2-professional': {'call_time': '10m0s'},\n    'v2-standard': {'call_time': '10m0s'}},\n   'lifecycle': [{'id': 'available', 'start_date': '2024-10-16'}]}]}"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": "from langchain_ibm import WatsonxEmbeddings\nfrom ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\n\nembeddings = WatsonxEmbeddings(\n    model_id=EmbeddingTypes.IBM_SLATE_30M_ENG.value,\n    url=credentials[\"url\"],\n    apikey=credentials[\"apikey\"],\n    project_id=project_id\n    )\ndocsearch = Chroma.from_documents(texts, embeddings)",
            "metadata": {
                "id": "3b80714f-d184-49d2-bdf5-bd8ed4b7363d"
            },
            "outputs": [],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": "#### Compatibility watsonx.ai Embeddings with LangChain\n\n LangChain retrievals use `embed_documents` and `embed_query` under the hood to generate embedding vectors for uploaded documents and user query respectively.",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<a id=\"models\"></a>\n## Foundation Models on `watsonx.ai`",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "markdown",
            "source": "IBM watsonx foundation models are among the <a href=\"https://python.langchain.com/docs/integrations/llms/watsonxllm\" target=\"_blank\" rel=\"noopener no referrer\">list of LLM models supported by Langchain</a>. This example shows how to communicate with <a href=\"https://newsroom.ibm.com/2023-09-28-IBM-Announces-Availability-of-watsonx-Granite-Model-Series,-Client-Protections-for-IBM-watsonx-Models\" target=\"_blank\" rel=\"noopener no referrer\">Granite Model Series</a> using <a href=\"https://python.langchain.com/docs/get_started/introduction\" target=\"_blank\" rel=\"noopener no referrer\">Langchain</a>.",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "### Defining model\nYou need to specify `model_id` that will be used for inferencing:",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n\nmodel_id = ModelTypes.GRANITE_13B_CHAT_V2",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "683d77fa-f468-4a9d-9ded-38ec946c2547"
            },
            "outputs": [],
            "execution_count": 16
        },
        {
            "cell_type": "markdown",
            "source": "### Defining the model parameters\nWe need to provide a set of model parameters that will influence the result:",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\nfrom ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n\nparameters = {\n    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n    GenParams.MIN_NEW_TOKENS: 1,\n    GenParams.MAX_NEW_TOKENS: 100,\n    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"]\n}",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "e57a67de-9eeb-4ffa-9849-9acd1a97807d"
            },
            "outputs": [],
            "execution_count": 17
        },
        {
            "cell_type": "markdown",
            "source": "### LangChain CustomLLM wrapper for watsonx model\nInitialize the `WatsonxLLM` class from Langchain with defined parameters and `ibm/granite-13b-chat-v2`. ",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "from langchain_ibm import WatsonxLLM\n\nwatsonx_granite = WatsonxLLM(\n    model_id=model_id.value,\n    url=credentials.get(\"url\"),\n    apikey=credentials.get(\"apikey\"),\n    project_id=project_id,\n    params=parameters\n)",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "69c1de72-2c31-4cc7-91df-259f8d93e90e"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:415: LifecycleWarning: Model 'ibm/granite-13b-chat-v2' is in deprecated state from 2024-11-04 until 2025-02-03. IDs of alternative models: None. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n  warnings.warn(\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 18
        },
        {
            "cell_type": "markdown",
            "source": "<a id=\"predict\"></a>\n## Generate a retrieval-augmented response to a question",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "markdown",
            "source": "Build the `RetrievalQA` (question answering chain) to automate the RAG task.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "from langchain.chains import RetrievalQA\n\nqa = RetrievalQA.from_chain_type(llm=watsonx_granite, \n                                 chain_type=\"stuff\", \n                                 retriever=docsearch.as_retriever(),\n                                return_source_documents=True)",
            "metadata": {
                "id": "9994ba82-2d8d-4214-8811-68b1c3bad75d"
            },
            "outputs": [],
            "execution_count": 19
        },
        {
            "cell_type": "code",
            "source": "RetrievalQA",
            "metadata": {
                "id": "5560e714-635b-4ff7-99a3-93d1bc093b50"
            },
            "outputs": [
                {
                    "execution_count": 20,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "langchain.chains.retrieval_qa.base.RetrievalQA"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 20
        },
        {
            "cell_type": "markdown",
            "source": "## Generate a retrieval-augmented response to a question",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "query = \"What did the president say about Ketanji Brown Jackson\"\noutput = qa.invoke(query)\nanswer = output[\"result\"]\ncontext = [item.page_content for item in output[\"source_documents\"]]",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                },
                "id": "ed2c7353-f2fc-4116-9419-4222cc8bb440"
            },
            "outputs": [],
            "execution_count": 21
        },
        {
            "cell_type": "code",
            "source": "print(query)",
            "metadata": {
                "id": "73eb7350-c2ee-412e-b2b1-0d612ecf636b"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "What did the president say about Ketanji Brown Jackson\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 22
        },
        {
            "cell_type": "code",
            "source": "print(answer)",
            "metadata": {
                "id": "9e91d727-b578-40f7-826f-6f3a460ee041"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": " The president said, \"One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\" This statement was made in reference to Ketanji Brown Jackson, who was nominated by the president to serve on the United States Supreme Court.\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 23
        },
        {
            "cell_type": "code",
            "source": "print(context)",
            "metadata": {
                "id": "2c40a798-a2cc-45bd-80c1-a1567ee0ae55"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "['Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.', 'And for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn\u2019t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we\u2019ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I\u2019m offering a Unity Agenda for the Nation. Four big things we can do together.  \\n\\nFirst, beat the opioid epidemic.', 'And my report is this: the State of the Union is strong\u2014because you, the American people, are strong. \\n\\nWe are stronger today than we were a year ago. \\n\\nAnd we will be stronger a year from now than we are today. \\n\\nNow is our moment to meet and overcome the challenges of our time. \\n\\nAnd we will, as one people. \\n\\nOne America. \\n\\nThe United States of America. \\n\\nMay God bless you all. May God protect our troops.', 'And built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.  \\n\\nWe will meet the test. \\n\\nTo protect freedom and liberty, to expand fairness and opportunity. \\n\\nWe will save democracy. \\n\\nAs hard as these times have been, I am more optimistic about America today than I have been my whole life. \\n\\nBecause I see the future that is within our grasp. \\n\\nBecause I know there is simply nothing beyond our capacity. \\n\\nWe are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \\n\\nThe only nation that can be defined by a single word: possibilities. \\n\\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union.']\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 24
        },
        {
            "cell_type": "markdown",
            "source": "Exercise: Try writing your own query and print out how many pieces of context are used",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "query = \"\"\nnum_context = 0\nprint(num_context)",
            "metadata": {
                "id": "d99812fd-5c8c-40b3-9b4b-e38dfdb82f3e"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "0\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 25
        },
        {
            "cell_type": "markdown",
            "source": "## Metrics",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "Use an LLM to calculate answer relevance",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "def answer_relevance(model, query, rag_response):\n\n    template: str = f\"\"\"[INST] Your task is to ascertain the relevance of the provided answer by comparing it against the given query. You are to answer with either YES or NO:\n        - Answer YES if the answer accurately aligns with or is relevant to any aspect of the query, irrespective of other unrelated content.\n        - Answer NO if the answer does not align with the query or introduces information not relevant to the query, indicating a potential hallucination or factual inaccuracy.\n        Avoid providing any additional explanations with your YES or NO response.\n\n        Information: {rag_response}\n        Query: {query}\n        Answer:[/INST]\"\"\"\n\n    # print(template)\n    # print(\"-------\")\n    evaluate_response = model.generate([template])\n    # print(evaluate_response)\n    \n    return 'YES' in evaluate_response.generations[0][0].text.upper()   ",
            "metadata": {
                "id": "5cd74596-28a1-42b2-a7a8-d3648e7c1597"
            },
            "outputs": [],
            "execution_count": 26
        },
        {
            "cell_type": "code",
            "source": "answer_relevance(watsonx_granite, query, answer)",
            "metadata": {
                "id": "fb2f4135-c253-454d-b540-63a99a42f6f1"
            },
            "outputs": [
                {
                    "execution_count": 27,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 27
        },
        {
            "cell_type": "code",
            "source": "# Note that the model is able to tell when the answer has nothing to do with the query\nanswer_relevance(watsonx_granite, query, \"nonsensical answer\")",
            "metadata": {
                "id": "8eaf629b-175b-443e-8446-d24b75eba8ba"
            },
            "outputs": [
                {
                    "execution_count": 28,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "False"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 28
        },
        {
            "cell_type": "code",
            "source": "# Note that the model is NOT able to tell when the query is not relevant to the answer \nanswer_relevance(watsonx_granite, \"random query\", answer)",
            "metadata": {
                "id": "c7953829-e8df-4794-9601-3b85fd4b713a"
            },
            "outputs": [
                {
                    "execution_count": 29,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "False"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 29
        },
        {
            "cell_type": "markdown",
            "source": "# Exercises:\n\n1. Create similar functions for both faithfulness and context relevance\n\n2. Create a list of questions for this dataset or for your own dataset\n\n3. Create a function to compute average evaluation metrics for all the questions. These will be your RAG triad metrics.\n\n4. Use such function to evaluate different RAG techniques (HyDe, fusion, query transformations, parent-child, etc.)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "def my_answer_relevance1(model, query, rag_response):\n\n    template: str = f\"\"\"[INST] Your task is to determine if an answer to a given question is relevant. You are to answer with either YES or NO:\n        - Answer YES if the answer accurately aligns with the question\n        - Answer NO if the answer does not align with the question or introduces information not relevant to the quesiton.\n        Avoid providing any additional explanations with the YES or NO response.\n\n        Information: {rag_response}\n        Query: {query}\n        Answer:[/INST]\"\"\"\n\n    # print(template)\n    # print(\"-------\")\n    evaluate_response = model.generate([template])\n    # print(evaluate_response)\n    \n    return 'YES' in evaluate_response.generations[0][0].text.upper()   ",
            "metadata": {
                "id": "b3d04b90-cda0-417a-8bff-aea510809b94"
            },
            "outputs": [],
            "execution_count": 30
        },
        {
            "cell_type": "code",
            "source": "my_answer_relevance1(watsonx_granite, query, \"nonsensical answer\")",
            "metadata": {
                "id": "a3efc36b-66bc-4a4b-b8dc-9778943e9dc7"
            },
            "outputs": [
                {
                    "execution_count": 32,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "False"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 32
        },
        {
            "cell_type": "code",
            "source": "my_answer_relevance1(watsonx_granite, query, answer)",
            "metadata": {
                "id": "8ceab613-9fd5-4fab-94d2-80f469fece73"
            },
            "outputs": [
                {
                    "execution_count": 33,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 33
        },
        {
            "cell_type": "code",
            "source": "my_answer_relevance1(watsonx_granite, \"random query\", answer)",
            "metadata": {
                "id": "674639f6-fbdc-44cc-9442-ed66e1f158fc"
            },
            "outputs": [
                {
                    "execution_count": 34,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "False"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 34
        },
        {
            "cell_type": "code",
            "source": "# New questions for the data set\nnew_questions = [ \n\"What is the president asking the Senate to do tonight\",\n\"Who gave their support to Ketanji Jackson\",\n\"Who gave their support to Ketanji Brown Jackson\",\n\"Who are the members of NATO mentioned in the text\" ]\n",
            "metadata": {
                "id": "e18d7b2d-4711-4216-b980-08cbf2a5ca9c"
            },
            "outputs": [],
            "execution_count": 52
        },
        {
            "cell_type": "code",
            "source": "\nfor q in new_questions:\n    output = qa.invoke(q)\n    answer = output[\"result\"]\n    print( \"Question: \" + q + \" Answer: \" + answer ) \n\n    print (\"Relevance: \" + str(my_answer_relevance1(watsonx_granite, q, answer)))",
            "metadata": {
                "id": "b6b72afe-5ef4-44fd-9370-51fc975d9885"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Question: What is the president asking the Senate to do tonight Answer:  The president is asking the Senate to pass the Freedom to Vote Act, the John Lewis Voting Rights Act, and the Disclose Act.\n\nExplanation: The president's speech includes a call for the Senate to pass several pieces of legislation. Specifically, he mentions the Freedom to Vote Act, the John Lewis Voting Rights Act, and the Disclose Act. These are the bills that the president is asking the Senate to pass tonight.\nRelevance: True\nQuestion: Who gave their support to Ketanji Jackson Answer:  President Joe Biden\nRelevance: False\nQuestion: Who gave their support to Ketanji Brown Jackson Answer:  A broad range of support - from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\nRelevance: True\nQuestion: Who are the members of NATO mentioned in the text Answer:  The members of NATO mentioned in the text are Poland, Romania, Latvia, Lithuania, and Estonia.\nRelevance: True\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 53
        },
        {
            "cell_type": "code",
            "source": "print ( query)",
            "metadata": {
                "id": "03b67d0c-3b16-4d68-aa5a-ae905d745024"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "What is the president asking the Senate to do tonight\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 51
        },
        {
            "cell_type": "code",
            "source": "print (answer)",
            "metadata": {
                "id": "6e14f41b-ba63-4c4d-9400-d4e61da641d7"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": " The president is asking the Senate to pass the Freedom to Vote Act, the John Lewis Voting Rights Act, and the Disclose Act.\n\nExplanation: The president's speech includes a call for the Senate to pass several pieces of legislation. Specifically, he mentions the Freedom to Vote Act, the John Lewis Voting Rights Act, and the Disclose Act. These are the bills that the president is asking the Senate to pass tonight.\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 40
        },
        {
            "cell_type": "code",
            "source": "print( context)",
            "metadata": {
                "id": "526aad46-d9ac-4afe-9254-d073829d10a2"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "['Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.', 'And for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn\u2019t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we\u2019ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I\u2019m offering a Unity Agenda for the Nation. Four big things we can do together.  \\n\\nFirst, beat the opioid epidemic.', 'And built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.  \\n\\nWe will meet the test. \\n\\nTo protect freedom and liberty, to expand fairness and opportunity. \\n\\nWe will save democracy. \\n\\nAs hard as these times have been, I am more optimistic about America today than I have been my whole life. \\n\\nBecause I see the future that is within our grasp. \\n\\nBecause I know there is simply nothing beyond our capacity. \\n\\nWe are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \\n\\nThe only nation that can be defined by a single word: possibilities. \\n\\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union.', 'Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia\u2019s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.']\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 41
        },
        {
            "cell_type": "markdown",
            "source": "<a id=\"summary\"></a>\n## Summary and next steps\n\n You successfully completed this notebook!.\n \n You learned how to answer question using RAG using watsonx and LangChain.\n \nCheck out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. ",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        },
        {
            "cell_type": "markdown",
            "source": "Copyright \u00a9 2023, 2024 IBM. This notebook and its source code are released under the terms of the MIT License.",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            }
        }
    ]
}